import re
from typing import List, Dict
from src.token_counter import TokenCounter
from src.file_processor import FileProcessor
from src.llm_agent import LLMInvoke
from src.chunker import Chunker
from src.map_reduce.concept_mapper import ConceptMapper
from src.map_reduce.concept_combiner import ConceptCombiner


class ConceptReducer:
    """
    Reduces detailed concept maps into a concise yet comprehensive set of concepts.
    Provides structured output with full-sentence summaries for each concept.
    """
    def __init__(self, llm_invoke):
        self.llm_invoke = llm_invoke

    @staticmethod
    def to_dicts(parsed_concepts: List[str]) -> List[Dict[str, str]]:
        """
        Convert parsed concept strings into list of dictionaries with 'concept' and 'summary'.
        """
        result = []
        for c in parsed_concepts:
            # Remove leading number like "1. "
            clean = re.sub(r'^\d+\.\s*', '', c).strip()

            # Split into "concept name" and "summary"
            if ':' in clean:
                concept, summary = clean.split(':', 1)
                concept = concept.strip(" *")   # remove bold markers & extra spaces
                summary = summary.strip()
            else:
                concept = clean
                summary = ""

            result.append({"concept": concept, "summary": summary})
        return result
        
    @staticmethod
    def parse_concepts(reduced: str) -> List[str]:
        """
        Split the reduced concepts string into individual concept entries.
        """
        concepts = []
        lines = reduced.split('\n')
        current = ''
        for line in lines:
            line_stripped = line.strip()
            if line_stripped and line_stripped[0].isdigit() and '.' in line_stripped[:3]:
                if current:
                    concepts.append(current.strip())
                current = line
            else:
                current += '\n' + line
        if current:
            concepts.append(current.strip())
        return concepts

    def reduce(self, context: str) -> str:
        prompt = f"""
        Instructions:
        You are reducing sets of detailed concept maps, a concise yet comprehensive list of important
        concepts, generated by extracting concepts from a document and potentially combining subsets of
        them that are relevant to each other.
        The goal is to create a structured resource that fully captures the essence of the material for testing
        and teaching purposes.
        Your task is to:
        - Identify the most critical concepts from the detailed concept map.
        - Provide a full-sentence summary for each concept that explains its significance, its relationship
        to other concepts, and any relevant examples or applications.
        - Ensure that the summaries are clear, self-contained, and detailed enough to aid in
        understanding without requiring additional context.
        - If necessary, combine related concepts into a single summary. Some of the concept maps have
        broader headings that can be used to guide this process.

        Here is the detailed concept map:

        Context:
        {context}
        Respond with a structured list where each important concept is followed by its full-sentence, detailed
        summary. For example:
        1. Concept Name: [Detailed full-sentence summary explaining the concept, its relevance, and any
        examples or applications.]
        2. Another Concept: [Detailed full-sentence summary explaining this concept, its connections to
        other ideas, and its role in understanding the material.]
        Continue in this format for all important concepts."""

        result = self.llm_invoke.llm_response(prompt)
        reduced = result["answer"]
        parsed_reduced_concepts=self.parse_concepts(reduced)
        reduced_list =self.to_dicts(parsed_reduced_concepts)
        return reduced_list
    
# usage
if __name__ == "__main__":

    input_path = "./notes.pdf" # Your file 's path
    file_processor = FileProcessor()
    documents, num_files = file_processor.process(input_path)
    
    chunker = Chunker(chunk_size=12000, chunk_overlap=1200)
    chunks = chunker.split_documents(documents)
    
    llm_invoke = LLMInvoke()
    main_concept_extractor = ConceptMapper(llm_invoke, max_workers=8)
    concepts_Map_list = main_concept_extractor.extract(chunks)


    MAX_TOKENS = 100000  # Adjust for your LLM
    counter = TokenCounter()
    combiner = ConceptCombiner(llm_invoke, counter, MAX_TOKENS)
    final_main_ideas = combiner.combine_concepts(concepts_Map_list)


    parsed_reducer=ConceptReducer(llm_invoke)
    reduced=parsed_reducer.reduce(final_main_ideas)
    print("len of produced list of dict",len(reduced))
    print(reduced)